---
layout: distill
title: Computer Use Survey - A Visual Survey of Computer Use Agents
description: A comprehensive survey exploring the evolution and current state of AI agents that interact with computers and web interfaces, from early reinforcement learning to modern LLM-based systems.
tags: ai agents computer-use web-agents llm
giscus_comments: false
date: 2026-04-27
featured: true
mermaid:
  enabled: true
  zoomable: true
toc:
  - name: Authors' Note
  - name: Introduction
  - name: What is Computer Use
  - name: Environments and Datasets
  - name: Models and Methods
  - name: Discussion
  - name: Citation Information

authors:
  - name: Kenneth Marino
    affiliations:
      name: Original Author
  - name: Ana Marasović
    affiliations:
      name: Original Author

bibliography: papers.bib

_styles: >
  .fake-img {
    background: #bbb;
    border: 1px solid rgba(0, 0, 0, 0.1);
    box-shadow: 0 0px 4px rgba(0, 0, 0, 0.1);
    margin-bottom: 12px;
  }
  .fake-img p {
    font-family: monospace;
    color: white;
    text-align: left;
    margin: 12px 0;
    text-align: center;
    font-size: 16px;
  }
---

## Authors' Note

I was originally planning to write a full survey paper with my collaborator Ana Marasović as a way for us to get up to speed before we worked on a new project in the area (more on this soon I hope). Unfortunately, I got busy preparing to start my faculty position and we just got scooped. There are now quite a few papers on LLM Agents and more specifically Computer Use. This took a bit of the wind out of our sails, but we wanted to still talk about some of the stuff we learned and present it in an engaging way.

So we present for you here, a computer-friendly survey of computer use survey. We hope this is a useful resource for people. Before we begin, here are some of those great surveys we recommend you check out!

Special thanks to Dai-Jie Wu who provided valuable feedback and helped debug browser compatability issues.

### Related Surveys

**A Comprehensive Survey of Agents for Computer Use: Foundations, Challenges, and Future Directions**
- Sager, P., et al. (2025). [arXiv:2501.16150](https://arxiv.org/abs/2501.16150)

**A Survey on Large Language Model based Autonomous Agents**
- Wang, L., et al. (2025). [arXiv:2308.11432](https://arxiv.org/abs/2308.11432)

**OS Agents: A Survey on MLLM-based Agents for Computer, Phone and Browser Use**
- Hu, X., et al. ACL (2025). [Paper PDF](https://os-agent-survey.github.io/paper.pdf)

**Survey on Evaluation of LLM-based Agents**
- Yehudai, A., et al. (2025). [arXiv:2503.16416](https://arxiv.org/abs/2503.16416)

There are also a number of websites which track new papers and models such as [awesome-computer-use](https://github.com/ranpox/awesome-computer-use) which serve as an ongoing reference.

---

## Introduction

In the last few years, and particularly in the most recent past year, AI systems which operate on the web and in computer environments have become a significant topic of study, for both academia and industry. If readers skim the citations in this review, they will likely notice that many of the works are extremely recent, most within the past year.

The goal of this survey is first to organize much of the historical and recent work on Computer Use Agents. First, we define exactly what we mean by "Computer Use". We then define and categorize different environments, datasets and evaluations for Computer Use Agents. Next, we discuss the methodological work in this area focusing in particular on the recent trend of "LLM Agents" and provide an accessible explanation of this class of systems and trends within this research. Finally, we discuss ongoing trends, areas for improvement and possible safety and ethical concerns brought about by this research.

### What Shaped the Interest?

So what has shaped this sudden interest in Computer Use Agents in the first place? What goals are academic and industry researchers trying to serve? 

The first explanation is that the advent of extremely capable language and language and vision models (LLMs / VLMs) has made the goal of autonomous computer use agents suddenly quite plausible. These models, trained now on trillions of tokens scraped from the web, are incredibly powerful few- and zero-shot learners able to with little or no new training data be generally proficient at many language tasks, making them adaptable to many different problems. 

Computer use is not only difficult in terms of being a long-horizon sequential decision-making problem, it is also linguistically challenging and knowledge-laden. Before these large-scale training models, language problems required models to be trained from scratch, language understanding was often limited and brittle and few-shot reasoning was almost unheard of. This makes it hard to do these computer use tasks.

Take a popular web use task example: booking an airline ticket. To solve the problem, you first have to be able to precisely understand a user's request: what airline they prefer, when they want to travel, etc. The agent also must have quite a bit of both commonsense and specific knowledge about airline ticket purchasing to accomplish this. The agent needs to not only understand the request and know how to navigate the airline website, it also needs to understand things like "I should not book a $10k ticket." 

With these capable LLMs, we not only have a backbone which has general capability that can start to make progress on the task, we have these essential commonsense capabilities to make Web Use Agents possible.

### Motivations

While the precise timing of this work can be explained by the arrival of these capable models, we should also ask what people are trying to accomplish with computer use agents. 

Many papers point to **automating routine, boring or time consuming tasks** as a motivation. Many works list automation of tedious tasks or enhancing user experiences as a motivation. The other common motivations are **accessibility**; making computers and the Internet more generally accessible to those with disabilities. We elaborate on this further in the Discussion section.

---

## What is Computer Use

First, we define what we mean here by a "Computer Use" AI system or Computer Use Agent. By this we mean an **agent that interacts dynamically with a computer system or web interface**. In the MDP formulation, an agent is a decision maker that observes an environment and takes actions.

### Key Definitions

**AGENT** - The learner and decision maker. As Sutton and Barto define: "The learner and decision maker is called the agent. The thing it interacts with, comprising everything outside the agent, is called the environment." These interact continually. The agent receives some representation of the environment's state and on that basis selects an action.

**ENVIRONMENT** - Everything outside the agent. The environment responds to the agent's actions and presents a new state to the agent. The environment also gives rise to rewards, special numerical values that the agent seeks to maximize over time through its choice of actions. In computer use, this includes operating systems, web browsers, applications, and interfaces.

**OBSERVATIONS** - Partial information about state. As Sutton and Barto note: "Observations — signals that depend on its [environment's] state but, like a robot's sensors, provide only partial information about it." In computer use, these might be screenshots, DOM trees, or accessibility information.

**EXECUTION VS. NON-EXECUTION** - Dynamic vs. static evaluation. Execution environments allow agents to dynamically interact and receive real-time feedback (e.g., live websites, VMs). Non-execution environments evaluate against pre-recorded traces or static snapshots without dynamic interaction.

**INTERFACES & TOOLS** - Different ways to interact. The environment includes everything an agent can interact with through distinct interfaces and tools. For example: using the browser interface to access Google Maps, the terminal interface to run git commands, or the chat interface to clarify user intent.

**AGENT'S HOST** - Where the agent operates. The physical or virtual machine where the agent is deployed and operates (e.g., a developer's laptop). The local workspace is the isolated environment specific to the agent within the host (e.g., a containerized Docker environment).

---

## Environments and Datasets

The landscape of Computer Use research spans diverse environments, from desktop operating systems to web browsers and mobile platforms. Each environment presents unique challenges and opportunities for developing autonomous agents.

We divide the datasets into several broad categories:

1. **Computer and OS Control** - Environments which give more or less full simulated access to a computer or operating system
2. **Web Control and Navigation** - Environments where access is mostly to the web (live or statically defined pages)
3. **Text-Only Web Environments** - Specifically text-only versions of web environments
4. **Web QA and Classification** - Datasets which ask static questions or classifications on web pages
5. **Coding and Assistant Tasks** - For coding tasks and the broad category of assistant tasks using Computer Use elements

We realize that the category "web browsing" is somewhat vague. It can include tasks involved with changing the settings of a browser such as Chrome and tasks requiring finding information on the web. Similarly, even what is meant by the web can be very different. This can mean access to a few websites such as in VisualWebArena or access to the entire web.

### Notable Datasets and Benchmarks

**OSWorld** - Benchmarking Multimodal Agents for Open-Ended Tasks in Real Computer Environments

**AndroidWorld** - A Dynamic Benchmarking Environment for Autonomous Agents

**WebArena** - A Realistic Web Environment for Building Autonomous Agents

**VisualWebArena** - Evaluating Multimodal Agents on Realistic Visual Web Tasks

**Mind2Web** - Towards a Generalist Agent for the Web

**Windows Agent Arena** - Evaluating Multi-modal OS Agents at Scale

**WorkArena** - How Capable Are Web Agents at Solving Common Knowledge Work Tasks?

**SWE-bench** - Can Language Models Resolve Real-world Github Issues?

**AssistantBench** - Can Web Agents Solve Realistic and Time-Consuming Tasks?

### Observations on Datasets

Unlike with many large-scale datasets in other fields such as ImageNet, these datasets are often entirely annotated by the researchers themselves (often graduate students). This often makes scaling these datasets quite challenging and puts more burden on students to create these datasets. Specialized tools such as AgentNet have been developed to try to aid in the annotation process, but the work is still highly specialized.

We found it actually quite difficult to count the number of tasks versus number of instances. In many datasets, there is no real distinction made: each query to a web agent is considered a task and there is exactly one instance of that task. Some of these tasks can be similar or overlap, but there is no categorization of similar tasks or instances.

---

## Models and Methods

In this section we discuss the models and methodologies used in the field from the pre-LLM era to modern Computer Use LM Agents.

### Pre-LLM Work

Inherent to this problem is taking repeated actions over time on some representation of a computer interface or website. Naturally, then, works have framed their methodology through the agent/environment paradigm.

#### Evolution of Pre-LLM Computer Use Research

**2000s: Classical Planning Era**
- The earliest works used classical planning techniques and cognitive architectures
- Even from this early stage the problem was framed under an agent-environment paradigm
- Key Technologies: STRIPS, Classical Planning, Cognitive Architectures, Symbolic AI

**2010s-2017: Early RL Revolution**
- Reinforcement Learning became the dominant paradigm
- This line of work took automatic, self-contained reward environments and trained models from scratch to predict optimal actions
- Key works: End-to-End Goal-Driven Web Navigation (2016), World of Bits (2017), AndroidEnv (2017)
- Key Technologies: Deep Q-Networks, Policy Gradients, OpenAI Universe, MiniWoB

**2018-2019: Advanced RL Techniques**
- Sophisticated approaches emerged including curriculum learning, curiosity-driven exploration, and hierarchical RL
- Behavior cloning from human demonstrations became common
- Key Technologies: Workflow-Guided Exploration, Curriculum Learning, Hierarchical RL, DOM Understanding

**2020-2022: Behavior Cloning & Scale**
- Focus shifted to collecting human traces and using behavior cloning
- Large-scale datasets emerged
- Field prepared for the LLM revolution
- Key works: WebGPT (2021), Learning to Navigate Wikipedia by Taking Random Walks (2022)
- Key Technologies: Human Feedback, Behavior Cloning, Large-Scale Datasets, Text-only Environments

### Computer Use LM Agents

As LLMs and VLMs began to scale on massive amounts of web data and thus became far more capable on language and vision tasks, approaches directly using these models as a backbone began to dominate. This line of work is characterized by frameworks which operate by utilizing LLM's ability to call tools to have the LLM call external tools and capabilities (such as OCR modules, episodic memory modules) and critically to call itself as a tool.

These papers are often called "agents" or "agentic" to mean that the system can take repeated actions over time by creating a finite state machine construction in such a way that the system is able to repeat a cycle of reading the task query, planning, interpreting the current input and taking actions in the environment. This bears some resemblance to the sense-think-act cycle in robotics.

#### Typical LLM Agent Architecture

<div class="fake-img l-page">
  <p>LLM Agent Control Flow Diagram</p>
</div>

The typical control flow shows:
1. User query is taken as input to an LLM prompted to act as a planning module
2. After an initial plan, control is passed to the LLM prompted to plan each step
3. Other modules load and interpret the input and decide the action
4. The input can be a direct image, OCR outputs, parsed HTML, DOM elements, or other representations
5. The action is decided and passed to a module which interprets the LLM output string as an environment action
6. This loop continues until the planner decides the agent has fulfilled the user query

#### Common Components

All Computer Use LM Agents have in common:

1. **An LLM or VLM backbone** - As well as any software that handles API calls if using an external service
2. **The firmament (or scaffolding)** - The finite state machine that decides the control flow and the prompting used for different LLM components
3. **External tools or modules** - Additional capabilities like episodic memory, web knowledge, or code interpreters

### Base Models for LLM Agents

#### Fixed Base Models

The first category of work does not train the LLM backbone, but relies on innovations in the firmament components or adding new modules such as OCR. Much of the early LLM agent work on web agents uses prompted only GPT-4(V) as at the time of its release it was one of the most capable models. Later much of the non-training work switched over to GPT-4o due to greater affordability and performance. Claude-3 and Claude-3.5 and GPT-4-Turbo are other popular choices.

#### Supervised Finetuning

Because base VLMs and LLMs are trained on typical web images and text, certain text and images may be out of distribution and models will struggle on these tasks. This is often the case for web tasks as well, so several works have looked to train models for this task:

- **CogAgent** - Adds a high-resolution image stack to CogVLM and finetunes on a large-scale dataset of GUI and OCR tasks
- **OS-ATLAS** - Creates a large GUI grounding corpus and finetunes Qwen2-VL and InternVL-2
- **xLAM** - A family of Large Action Models specifically trained for agent systems

#### RL Finetuning

Several works have looked at automatic exploration of web and OS environments for finetuning. These methods interact with the OS or Web environment directly to then update the model:

- Traces in the environment are created synthetically by using the dataset training set or prompting an LLM for a task
- Using the base LLM to generate actions in the environment
- Using another LLM to self-critique to determine if the task was accomplished successfully
- **WebRL** - Adopts a full RL training loop for exploring and fine-tuning base models, uses KL smoothing and replay buffer

### Firmament (Scaffolding)

Another critical part of web agent architectures are the control flow state machines and prompting techniques. This incorporates:

- **Prompting strategies** - Such as prompting agents to give responses in code
- **Additional modules** - Self reflection, episodic memory of related examples, hierarchical planning modules, online web search and narrative planning
- **Test-time search** - A*-like exploration of web actions, Reflective Monte Carlo Tree Search (R-MCTS), model-based planning

#### Input Representation

Great experimentation has occurred with input representations:

- **Set of marks** - Where an id is overlaid on the UI element of interest
- **Accessibility trees** - Built-in features in operating systems and browsers which tag UI elements with text
- **HTML** - Often reduced or filtered using Document Object Model (DOM) tree
- **Raw screenshots** - Direct image inputs
- Often several of these input types are combined together

The wide variety of inputs used by different models can create issues with evaluations and benchmarking. The same backbone model prompted differently and using different representations can have vastly different performances.

#### Action Space

Methods have a wide variety of ways of dealing with action spaces:

- **Low-level actions** - Atomic mouse (x, y) positions and click actions
- **Language-specified actions** - Templated language like `click(id)` or `jump_to(url, newtab)`
- **Tool-based actions** - Treating the computer action space as a tool with predefined web actions

With custom action spaces, prompts tell the LLM the set of available actions and some kind of parser or interpreter translates these language-specified actions to the environment.

### Proprietary Systems

Web and OS control agents are not only an academic topic, but an emerging product area for AI companies:

- **Google DeepMind's Project Mariner**
- **OpenAI's Operator**
- **Anthropic's Computer Use**

Unfortunately, some of these models are in limited release, either behind trusted user groups or premium subscriptions, making evaluation difficult. These projects have reported numbers on some popular computer use benchmarks, but none have released papers or detailed technical reports. Ultimately, these black-box releases are very relevant to the interest in computer use agents, but cannot be easily benchmarked or relied upon to contribute to the academic literature.

---

## Discussion

### Areas for Improvement

#### Performance Comparison

Here's a comparison of different methods on two popular benchmarks, WebArena and OSWorld:

| Method | WebArena | OSWorld |
|--------|----------|---------|
| GPT-4 | 14.4% | 12.24% |
| GPT-4o | 13.1% | 11.36% |
| WebRL | 49.1% | - |
| Agent S | - | 20.58% |
| OpenCUA | - | 34.8% |
| Seed1.5-VL | - | 40% |

One observation is that great improvements have been made on all of these tasks, but accuracies are still quite low, all below 60%. So what things might be holding models back?

#### Planning

One area where computer use agents often get stuck is planning. A common issue is that LLM agents will sometimes get stuck in a state and repeatedly try to perform some action unsuccessfully or being distracted by an irrelevant web element. Many works try to solve this with:
- Using an LLM as a "planner" 
- Relying on the LLM itself to recognize that it is stuck
- Using test-time search to escape loops

#### Input/Output Representation

Another issue is environment grounding. For agents which use raw pixel input, this is a problem of visual grounding: can the model understand what is in an image and where. Even methods using non-visual representations (HTML, DOM trees) have the same grounding problem.

Common issues include:
- Important UI elements not being recognized
- Failures of non-visual tools (Set-of-Marks, accessibility trees, DOMs)
- Accessibility trees or DOMs containing errors or missing labels
- VLMs not adequately trained on web images
- Out-of-domain image understanding problems

#### Lack of Training Data

One obvious issue may simply be that many base LLMs or VLMs are not well aligned to the task. While real attempts have been made to create larger datasets for training, especially for visual finetuning, one major issue in long-horizon RL problems is requiring a lot of data. Long trajectories can cause policies to suffer a distribution shift from the training trajectories, leading to poor performance.

#### Long-horizon Problems are Hard

Many web or computer tasks are fundamentally difficult because they are long-horizon action problems. We have a description of some task in language and expect agents to take many consecutive steps before resolving the query. 

In the Reinforcement Learning literature, there is a well-known issue of "sparse rewards" which makes it difficult for agents to explore properly. Another related problem is the Credit Assignment problem: "In applying such methods to complex problems, one encounters a serious difficulty-in distributing credit for success of a complex strategy among the many decisions that were involved" (Marvin Minsky).

### But Why Web Agents?

As discussed in the Introduction, the two most common goals for Computer Use Agents are related to **automation** and **accessibility**.

#### Automation

The automation motivation is compelling. As described in WebGPT: "Picture this scenario: You type in a task description, then relax and enjoy a cup of coffee while watching tasks like booking tickets online, conducting web searches, managing files, and creating PowerPoint presentations get completed automatically." This vision of seamless task automation drives much of the current research effort.

#### Accessibility Concerns

The other motivation is accessibility, with researchers stating that this line of work will "make digital devices more accessible". Several potential issues emerge however:

1. **Reliance on existing accessibility features** - Many current agents rely implicitly or explicitly on accessibility features already built into operating systems or the web to function. Unfortunately, 95.9% of webpages contain errors in accessibility including missing alt text in images or missing form input labels at around 57 errors per page.

2. **Disconnect from actual needs** - There can be a large disconnect between the use cases, datasets and models thought up by researchers (often mostly sighted people) and those actually important and useful to blind and visually impaired people. Future work which seeks to improve accessibility must use actual data and requirements from the blind to be genuinely helpful.

Nevertheless, the potential certainly exists in the future for these agents to be useful for accessibility, not just for those with visual impairment, but people with severe neuropathy or motor control symptoms as well as people with cognitive or memory issues. Computer use agents will first have to drastically improve in performance and researchers will have to work with health researchers, providers and affected people to develop truly useful accessibility features.

### Safety and Ethical Concerns

The emergence of more capable computer use agents has raised a number of new ethical and safety issues:

#### Malicious Use

One prominent issue is the possibility of Web Agents for malicious use. Hard-coded web agents (often called "bots") have already been cited as a major issue with "Scalper bots" being used to buy limited-quantity items and resold at massive markups. With more sophisticated bots, these concerns are even more acute:
- More adaptable and intelligent bots could override mechanisms like CAPTCHAs
- Web agents could help automate more web activities for fraudulent or malicious purposes

#### Privacy and Security

Computer use agents acting on behalf of users have access to extremely sensitive information such as:
- Users' profiles and passwords
- Financial transactions
- Social media messages
- Many other kinds of sensitive data

This information could accidentally or maliciously be accessed by the agent and sent to others. Mistakes could cause web agents to accidentally send un-encrypted passwords, or web agents could be deliberately designed to steal such information.

For a more thorough discussion of ethical issues involved in agents, see the blog post ["AI Agents Are Here. What Now?"](https://huggingface.co/blog/ethics-soc-7) which provides a detailed breakdown.

---

## Citation Information

For attribution in academic contexts, please cite this work as:

```
Marino, Kenneth and Marasović, Ana, "Computer Use Survey: A Visual Survey of Computer Use Agents", 2025.
```

### BibTeX citation

```bibtex
@misc{marino2025computeruse,
    author={Marino, Kenneth and Marasovi\'c, Ana},
    title={Computer Use Survey: A Visual Survey of Computer Use Agents},
    year={2025},
    url={https://kennethmarino.com/computeruse/computeruse.html}
}
```

---

## Acknowledgments

This survey was adapted from the original interactive web version created by Kenneth Marino and Ana Marasović. Claude Sonnet 4 was used to help build the original website. Special thanks to Dai-Jie Wu who provided valuable feedback and helped debug browser compatibility issues.

Original survey available at: [https://kennethmarino.com/computeruse/computeruse.html](https://kennethmarino.com/computeruse/computeruse.html)
