% Use this file for citations not found in the ACL Anthology (contained in "anthology.bib").

@article{rasooli-tetrault-2015,
    author    = {Mohammad Sadegh Rasooli and Joel R. Tetreault},
    title     = {Yara Parser: {A} Fast and Accurate Dependency Parser},
    journal   = {Computing Research Repository},
    volume    = {arXiv:1503.06733},
    year      = {2015},
    url       = {http://arxiv.org/abs/1503.06733},
    note    = {version 2}
}

@article{Ando2005,
	Acmid = {1194905},
	Author = {Ando, Rie Kubota and Zhang, Tong},
	Issn = {1532-4435},
	Issue_Date = {12/1/2005},
	Journal = {Journal of Machine Learning Research},
	Month = dec,
	Numpages = {37},
	Pages = {1817--1853},
	Publisher = {JMLR.org},
	Title = {A Framework for Learning Predictive Structures from Multiple Tasks and Unlabeled Data},
	Volume = {6},
	Year = {2005}
}

@inproceedings{zhouwebarena,
  title={WebArena: A Realistic Web Environment for Building Autonomous Agents},
  author={Zhou, Shuyan and Xu, Frank F and Zhu, Hao and Zhou, Xuhui and Lo, Robert and Sridhar, Abishek and Cheng, Xianyi and Ou, Tianyue and Bisk, Yonatan and Fried, Daniel and others},
  booktitle={The Twelfth International Conference on Learning Representations},
  year=2024,
}

@inproceedings{koh2024visualwebarena,
  title={VisualWebArena: Evaluating Multimodal Agents on Realistic Visual Web Tasks},
  author={Koh, Jing Yu and Lo, Robert and Jang, Lawrence and Duvvur, Vikram and Lim, Ming Chong and Huang, Po-Yu and Neubig, Graham and Zhou, Shuyan and Salakhutdinov, Ruslan and Fried, Daniel},
  booktitle={ICLR 2024 Workshop on Large Language Model (LLM) Agents},
  year={2024},
}

@article{deng2024mind2web,
  title={Mind2web: Towards a generalist agent for the web},
  author={Deng, Xiang and Gu, Yu and Zheng, Boyuan and Chen, Shijie and Stevens, Sam and Wang, Boshi and Sun, Huan and Su, Yu},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{boisvert2024workarena++,
  title={Workarena++: Towards compositional planning and reasoning-based common knowledge work tasks},
  author={Boisvert, L{\'e}o and Thakkar, Megh and Gasse, Maxime and Caccia, Massimo and Chezelles, De and Le Sellier, Thibault and Cappart, Quentin and Chapados, Nicolas and Lacoste, Alexandre and Drouin, Alexandre},
  journal={arXiv preprint arXiv:2407.05291},
  year={2024}
}

@article{pan2024webcanvas,
  title={WebCanvas: Benchmarking Web Agents in Online Environments},
  author={Pan, Yichen and Kong, Dehan and Zhou, Sida and Cui, Cheng and Leng, Yifei and Jiang, Bing and Liu, Hangyu and Shang, Yanyi and Zhou, Shuyan and Wu, Tongshuang and others},
  journal={arXiv preprint arXiv:2406.12373},
  year={2024}
}

@article{xie2024osworld,
  title={Osworld: Benchmarking multimodal agents for open-ended tasks in real computer environments},
  author={Xie, Tianbao and Zhang, Danyang and Chen, Jixuan and Li, Xiaochuan and Zhao, Siheng and Cao, Ruisheng and Hua, Toh Jing and Cheng, Zhoujun and Shin, Dongchan and Lei, Fangyu and others},
  journal={arXiv preprint arXiv:2404.07972},
  year={2024}
}

@article{kapoor2024omniact,
  title={OmniACT: A Dataset and Benchmark for Enabling Multimodal Generalist Autonomous Agents for Desktop and Web},
  author={Kapoor, Raghav and Butala, Yash Parag and Russak, Melisa and Koh, Jing Yu and Kamble, Kiran and Alshikh, Waseem and Salakhutdinov, Ruslan},
  journal={arXiv preprint arXiv:2402.17553},
  year={2024}
}

@article{rawles2024androidworld,
  title={AndroidWorld: A dynamic benchmarking environment for autonomous agents},
  author={Rawles, Christopher and Clinckemaillie, Sarah and Chang, Yifan and Waltz, Jonathan and Lau, Gabrielle and Fair, Marybeth and Li, Alice and Bishop, William and Li, Wei and Campbell-Ajala, Folawiyo and others},
  journal={arXiv preprint arXiv:2405.14573},
  year={2024}
}

@article{rawles2024androidinthewild,
  title={Androidinthewild: A large-scale dataset for android device control},
  author={Rawles, Christopher and Li, Alice and Rodriguez, Daniel and Riva, Oriana and Lillicrap, Timothy},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{toyama2021androidenv,
  title={Androidenv: A reinforcement learning platform for android},
  author={Toyama, Daniel and Hamel, Philippe and Gergely, Anita and Comanici, Gheorghe and Glaese, Amelia and Ahmed, Zafarali and Jackson, Tyler and Mourad, Shibl and Precup, Doina},
  journal={arXiv preprint arXiv:2105.13231},
  year={2021}
}

@article{li2024effects,
  title={On the Effects of Data Scale on Computer Control Agents},
  author={Li, Wei and Bishop, William and Li, Alice and Rawles, Chris and Campbell-Ajala, Folawiyo and Tyamagundlu, Divya and Riva, Oriana},
  journal={arXiv preprint arXiv:2406.03679},
  year={2024}
}

@article{bonatti2024windows,
  title={Windows agent arena: Evaluating multi-modal os agents at scale},
  author={Bonatti, Rogerio and Zhao, Dan and Bonacci, Francesco and Dupont, Dillon and Abdali, Sara and Li, Yinheng and Wagle, Justin and Koishida, Kazuhito and Bucker, Arthur and Jang, Lawrence and others},
  journal={arXiv preprint arXiv:2409.08264},
  year={2024}
}

@article{wang2024opendevin,
  title={Opendevin: An open platform for ai software developers as generalist agents},
  author={Wang, Xingyao and Li, Boxuan and Song, Yufan and Xu, Frank F and Tang, Xiangru and Zhuge, Mingchen and Pan, Jiayi and Song, Yueqi and Li, Bowen and Singh, Jaskirat and others},
  journal={arXiv preprint arXiv:2407.16741},
  year={2024}
}

@inproceedings{jimenezswe,
  title={SWE-bench: Can Language Models Resolve Real-world Github Issues?},
  author={Jimenez, Carlos E and Yang, John and Wettig, Alexander and Yao, Shunyu and Pei, Kexin and Press, Ofir and Narasimhan, Karthik R},
  booktitle={The Twelfth International Conference on Learning Representations},
  year=2024,
}

@misc{swebenchverifiedblog,
	author = {Neil Chowdhury and James Aung and Chan Jun Shern and Oliver Jaffe, Dane Sherburn and Giulio Starace and Evan Mays and Rachel Dias and Marwan Aljubeh and Mia Glaese and Carlos E. Jimenez and John Yang and Kevin Liu and Aleksander Madry},
	title = {{I}ntroducing {S}{W}{E}-bench {V}erified},
	howpublished = {\url{https://openai.com/index/introducing-swe-bench-verified/}},
	year = {2024},
}

@article{chen2024scienceagentbench,
  title={ScienceAgentBench: Toward Rigorous Assessment of Language Agents for Data-Driven Scientific Discovery},
  author={Chen, Ziru and Chen, Shijie and Ning, Yuting and Zhang, Qianheng and Wang, Boshi and Yu, Botao and Li, Yifei and Liao, Zeyi and Wei, Chen and Lu, Zitong and others},
  journal={arXiv preprint arXiv:2410.05080},
  year={2024}
}

@article{liu2024harnessing,
  title={Harnessing Webpage UIs for Text-Rich Visual Understanding},
  author={Liu, Junpeng and Ou, Tianyue and Song, Yifan and Qu, Yuxiao and Lam, Wai and Xiong, Chenyan and Chen, Wenhu and Neubig, Graham and Yue, Xiang},
  journal={arXiv preprint arXiv:2410.13824},
  year={2024}
}

@article{liu2024visualwebbench,
  title={VisualWebBench: How Far Have Multimodal LLMs Evolved in Web Page Understanding and Grounding?},
  author={Liu, Junpeng and Song, Yifan and Lin, Bill Yuchen and Lam, Wai and Neubig, Graham and Li, Yuanzhi and Yue, Xiang},
  journal={arXiv preprint arXiv:2404.05955},
  year={2024}
}

@inproceedings{pasupat-liang-2014-zero,
    title = "Zero-shot Entity Extraction from Web Pages",
    author = "Pasupat, Panupong  and
      Liang, Percy",
    editor = "Toutanova, Kristina  and
      Wu, Hua",
    booktitle = "Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jun,
    year = "2014",
    address = "Baltimore, Maryland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P14-1037",
    doi = "10.3115/v1/P14-1037",
    pages = "391--401",
}


@InProceedings{pmlr-v70-shi17a,
  title = 	 {World of Bits: An Open-Domain Platform for Web-Based Agents},
  author =       {Tianlin Shi and Andrej Karpathy and Linxi Fan and Jonathan Hernandez and Percy Liang},
  booktitle = 	 {Proceedings of the 34th International Conference on Machine Learning},
  pages = 	 {3135--3144},
  year = 	 {2017},
  editor = 	 {Precup, Doina and Teh, Yee Whye},
  volume = 	 {70},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {06--11 Aug},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v70/shi17a/shi17a.pdf},
  url = 	 {https://proceedings.mlr.press/v70/shi17a.html},
  abstract = 	 {While simulated game environments have greatly accelerated research in reinforcement learning, existing environments lack the open-domain realism of tasks in computer vision or natural language processing, which operate on artifacts created by humans in natural, organic settings. To foster reinforcement learning research in such settings, we introduce the World of Bits (WoB), a platform in which agents complete tasks on the Internet by performing low-level keyboard and mouse actions. The two main challenges are: (i) to curate a large, diverse set of interesting web-based tasks, and (ii) to ensure that these tasks have a well-defined reward structure and are reproducible despite the transience of the web. To do this, we develop a methodology in which crowdworkers create tasks defined by natural language questions and provide demonstrations of how to answer the question on real websites using keyboard and mouse; HTTP traffic is cached to create a reproducible offline approximation of the web site. Finally, we show that agents trained via behavioral cloning and reinforcement learning can successfully complete a range of our web-based tasks.}
}

@inproceedings{liu2018reinforcement,
  title={Reinforcement Learning on Web Interfaces using Workflow-Guided Exploration},
  author={Liu, Evan Zheran and Guu, Kelvin and Pasupat, Panupong and Shi, Tianlin and Liang, Percy},
  booktitle={International Conference on Learning Representations},
  year={2018}
}

@article{nogueira2016end,
  title={End-to-end goal-driven web navigation},
  author={Nogueira, Rodrigo and Cho, Kyunghyun},
  journal={Advances in neural information processing systems},
  volume={29},
  year={2016}
}

@article{yoran2407assistantbench,
  title={Assistantbench: Can web agents solve realistic and time-consuming tasks?}, year={2024},
  author={Yoran, Ori and Amouyal, Samuel Joseph and Malaviya, Chaitanya and Bogin, Ben and Press, Ofir and Berant, Jonathan},
  journal={URL https://arxiv. org/abs/2407.15711}
}

@article{press2024citeme,
  title={CiteME: Can Language Models Accurately Cite Scientific Claims?},
  author={Press, Ori and Hochlehnert, Andreas and Prabhu, Ameya and Udandarao, Vishaal and Press, Ofir and Bethge, Matthias},
  journal={arXiv preprint arXiv:2407.12861},
  year={2024}
}

@article{mialon2023gaia,
  title={Gaia: a benchmark for general ai assistants},
  author={Mialon, Gr{\'e}goire and Fourrier, Cl{\'e}mentine and Swift, Craig and Wolf, Thomas and LeCun, Yann and Scialom, Thomas},
  journal={arXiv preprint arXiv:2311.12983},
  year={2023}
}

@article{cao2024spider2,
  title={Spider2-V: How Far Are Multimodal Agents From Automating Data Science and Engineering Workflows?},
  author={Cao, Ruisheng and Lei, Fangyu and Wu, Haoyuan and Chen, Jixuan and Fu, Yeqiao and Gao, Hongcheng and Xiong, Xinzhuang and Zhang, Hanchong and Mao, Yuchen and Hu, Wenjing and others},
  journal={arXiv preprint arXiv:2407.10956},
  year={2024}
}

@article{pan2024autonomous,
  title={Autonomous evaluation and refinement of digital agents},
  author={Pan, Jiayi and Zhang, Yichi and Tomlin, Nicholas and Zhou, Yifei and Levine, Sergey and Suhr, Alane},
  journal={arXiv preprint arXiv:2404.06474},
  year={2024}
}

@article{kapoor2024ai,
  title={Ai agents that matter},
  author={Kapoor, Sayash and Stroebl, Benedikt and Siegel, Zachary S and Nadgir, Nitya and Narayanan, Arvind},
  journal={arXiv preprint arXiv:2407.01502},
  year={2024}
}

@article{gou2024navigating,
  title={Navigating the digital world as humans do: Universal visual grounding for gui agents},
  author={Gou, Boyu and Wang, Ruohan and Zheng, Boyuan and Xie, Yanan and Chang, Cheng and Shu, Yiheng and Sun, Huan and Su, Yu},
  journal={arXiv preprint arXiv:2410.05243},
  year={2024}
}

@inproceedings{agashe2024agent,
  title={Agent S: An Open Agentic Framework that Uses Computers Like a Human},
  author={Agashe, Saaket and Han, Jiuzhou and Gan, Shuyu and Yang, Jiachen and Li, Ang and Wang, Xin Eric},
  booktitle={NeurIPS 2024 Workshop on Open-World Agents},
  year={2024},
}

@misc{anthropicwebblog,
	author = {Anthropic},
	title = {Introducing computer use, a new Claude 3.5 Sonnet, and Claude 3.5 Haiku},
	howpublished = {https://www.anthropic.com/news/3-5-models-and-computer-use},
	year = {2024},
}

@misc{anthropicbuildingcublog,
	author = {Anthropic},
	title = {Developing a computer use model},
	howpublished = {https://www.anthropic.com/news/developing-computer-use},
	year = {2024},
}

@misc{projectmariner,
	author = {Google DeepMind},
	title = {Project Mariner},
	howpublished = {https://deepmind.google/technologies/project-mariner/},
	year = {2024},
}

@misc{computeruseagent,
	author = {OpenAI},
	title = {Project Mariner},
	howpublished = {https://openai.com/index/computer-using-agent/},
	year = {2025},
}


@misc{webaim,
	title = {WebAIM. The WebAIM Million.},
        key = {WebAIM},
	howpublished = {https://webaim.org/projects/million/},
	year = {2024},
}

@inproceedings{zhenggpt,
  title={GPT-4V (ision) is a Generalist Web Agent, if Grounded},
  year={2024},
  author={Zheng, Boyuan and Gou, Boyu and Kil, Jihyung and Sun, Huan and Su, Yu},
  booktitle={Forty-first International Conference on Machine Learning}
}

@article{sarch2024ical,
  title={Ical: Continual learning of multimodal agents by transforming trajectories into actionable insights},
  author={Sarch, Gabriel and Jang, Lawrence and Tarr, Michael J and Cohen, William W and Marino, Kenneth and Fragkiadaki, Katerina},
  journal={Advances in neural information processing systems},
  year={2024}
}

@article{murty2024bagel,
  title={BAGEL: Bootstrapping Agents by Guiding Exploration with Language},
  author={Murty, Shikhar and Manning, Christopher and Shaw, Peter and Joshi, Mandar and Lee, Kenton},
  journal={arXiv preprint arXiv:2403.08140},
  year={2024}
}

@article{zhang2024xlam,
  title={xlam: A family of large action models to empower ai agent systems},
  author={Zhang, Jianguo and Lan, Tian and Zhu, Ming and Liu, Zuxin and Hoang, Thai and Kokane, Shirley and Yao, Weiran and Tan, Juntao and Prabhakar, Akshara and Chen, Haolin and others},
  journal={arXiv preprint arXiv:2409.03215},
  year={2024}
}

@article{ou2024synatra,
  title={Synatra: Turning indirect knowledge into direct demonstrations for digital agents at scale},
  author={Ou, Tianyue and Xu, Frank F and Madaan, Aman and Liu, Jiarui and Lo, Robert and Sridhar, Abishek and Sengupta, Sudipta and Roth, Dan and Neubig, Graham and Zhou, Shuyan},
  journal={arXiv preprint arXiv:2409.15637},
  year={2024}
}

@inproceedings{hong2024cogagent,
  title={Cogagent: A visual language model for gui agents},
  author={Hong, Wenyi and Wang, Weihan and Lv, Qingsong and Xu, Jiazheng and Yu, Wenmeng and Ji, Junhui and Wang, Yan and Wang, Zihan and Dong, Yuxiao and Ding, Ming and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={14281--14290},
  year={2024}
}

@article{wang2023cogvlm,
  title={Cogvlm: Visual expert for pretrained language models},
  author={Wang, Weihan and Lv, Qingsong and Yu, Wenmeng and Hong, Wenyi and Qi, Ji and Wang, Yan and Ji, Junhui and Yang, Zhuoyi and Zhao, Lei and Song, Xixuan and others},
  journal={arXiv preprint arXiv:2311.03079},
  year={2023}
}

@article{chen2024far,
  title={How far are we to gpt-4v? closing the gap to commercial multimodal models with open-source suites},
  author={Chen, Zhe and Wang, Weiyun and Tian, Hao and Ye, Shenglong and Gao, Zhangwei and Cui, Erfei and Tong, Wenwen and Hu, Kongzhi and Luo, Jiapeng and Ma, Zheng and others},
  journal={Science China Information Sciences},
  volume={67},
  number={12},
  pages={220101},
  year={2024},
  publisher={Springer}
}

@article{yang2024swe,
  title={Swe-agent: Agent-computer interfaces enable automated software engineering},
  author={Yang, John and Jimenez, Carlos E and Wettig, Alexander and Lieret, Kilian and Yao, Shunyu and Narasimhan, Karthik and Press, Ofir},
  journal={arXiv preprint arXiv:2405.15793},
  year={2024}
}

@article{xia2024agentless,
  title={Agentless: Demystifying llm-based software engineering agents},
  author={Xia, Chunqiu Steven and Deng, Yinlin and Dunn, Soren and Zhang, Lingming},
  journal={arXiv preprint arXiv:2407.01489},
  year={2024}
}

@article{wang2024survey,
  title={A survey on large language model based autonomous agents},
  author={Wang, Lei and Ma, Chen and Feng, Xueyang and Zhang, Zeyu and Yang, Hao and Zhang, Jingsen and Chen, Zhiyuan and Tang, Jiakai and Chen, Xu and Lin, Yankai and others},
  journal={Frontiers of Computer Science},
  volume={18},
  number={6},
  year={2024},
  publisher={Higher Education Press Beijing}
}

@article{rahmanzadehgervi2024vision,
  title={Vision language models are blind},
  author={Rahmanzadehgervi, Pooyan and Bolton, Logan and Taesiri, Mohammad Reza and Nguyen, Anh Totti},
  journal={arXiv preprint arXiv:2407.06581},
  year={2024}
}

@article{wu2024atlas,
  title={OS-ATLAS: A Foundation Action Model for Generalist GUI Agents},
  author={Wu, Zhiyong and Wu, Zhenyu and Xu, Fangzhi and Wang, Yian and Sun, Qiushi and Jia, Chengyou and Cheng, Kanzhi and Ding, Zichen and Chen, Liheng and Liang, Paul Pu and others},
  journal={arXiv preprint arXiv:2410.23218},
  year={2024}
}

@article{aleithan2024swe,
  title={SWE-Bench+: Enhanced Coding Benchmark for LLMs},
  author={Aleithan, Reem and Xue, Haoran and Mohajer, Mohammad Mahdi and Nnorom, Elijah and Uddin, Gias and Wang, Song},
  journal={arXiv preprint arXiv:2410.06992},
  year={2024}
}

@article{zaheer2022learning,
  title={Learning to navigate wikipedia by taking random walks},
  author={Zaheer, Manzil and Marino, Kenneth and Grathwohl, Will and Schultz, John and Shang, Wendy and Babayan, Sheila and Ahuja, Arun and Dasgupta, Ishita and Kaeser-Chen, Christine and Fergus, Rob},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={1529--1541},
  year={2022}
}

@inproceedings{gurari2018vizwiz,
  title={Vizwiz grand challenge: Answering visual questions from blind people},
  author={Gurari, Danna and Li, Qing and Stangl, Abigale J and Guo, Anhong and Lin, Chi and Grauman, Kristen and Luo, Jiebo and Bigham, Jeffrey P},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={3608--3617},
  year={2018}
}

@article{hofmann2020robotic,
  title={Robotic process automation},
  author={Hofmann, Peter and Samp, Caroline and Urbach, Nils},
  journal={Electronic markets},
  volume={30},
  number={1},
  pages={99--106},
  year={2020},
  publisher={Springer}
}

@article{chen2024more,
  title={Are more llm calls all you need? towards scaling laws of compound inference systems},
  author={Chen, Lingjiao and Davis, Jared Quincy and Hanin, Boris and Bailis, Peter and Stoica, Ion and Zaharia, Matei and Zou, James},
  journal={arXiv preprint arXiv:2403.02419},
  year={2024}
}

@article{nakano2021webgpt,
  title={Webgpt: Browser-assisted question-answering with human feedback},
  author={Nakano, Reiichiro and Hilton, Jacob and Balaji, Suchir and Wu, Jeff and Ouyang, Long and Kim, Christina and Hesse, Christopher and Jain, Shantanu and Kosaraju, Vineet and Saunders, William and others},
  journal={arXiv preprint arXiv:2112.09332},
  year={2021}
}

@inproceedings{gurlearning,
  title={Learning to Navigate the Web},
  year=2019,
  author={Gur, Izzeddin and Rueckert, Ulrich and Faust, Aleksandra and Hakkani-Tur, Dilek},
  booktitle={International Conference on Learning Representations}
}

@article{xu2024theagentcompany,
  title={Theagentcompany: benchmarking llm agents on consequential real world tasks},
  author={Xu, Frank F and Song, Yufan and Li, Boxuan and Tang, Yuxuan and Jain, Kritanjali and Bao, Mengxue and Wang, Zora Z and Zhou, Xuhui and Guo, Zhitong and Cao, Murong and others},
  journal={arXiv preprint arXiv:2412.14161},
  year={2024}
}

@article{Yu2024ExACTTA,
  title={ExACT: Teaching AI Agents to Explore with Reflective-MCTS and Exploratory Learning},
  author={Xiao Yu and Baolin Peng and Vineeth Vajipey and Hao Cheng and Michel Galley and Jianfeng Gao and Zhou Yu},
  journal={ArXiv},
  year={2024},
  volume={abs/2410.02052},
  url={https://api.semanticscholar.org/CorpusID:273098809}
}

@inproceedings{wangexecutable,
  title={Executable Code Actions Elicit Better LLM Agents},
  author={Wang, Xingyao and Chen, Yangyi and Yuan, Lifan and Zhang, Yizhe and Li, Yunzhu and Peng, Hao and Ji, Heng},
  booktitle={Forty-first International Conference on Machine Learning}
}

@article{qi2024webrl,
  title={WebRL: Training LLM Web Agents via Self-Evolving Online Curriculum Reinforcement Learning},
  author={Qi, Zehan and Liu, Xiao and Iong, Iat Long and Lai, Hanyu and Sun, Xueqiao and Yang, Xinyue and Sun, Jiadai and Yang, Yu and Yao, Shuntian and Zhang, Tianjie and others},
  journal={arXiv preprint arXiv:2411.02337},
  year={2024}
}

@article{putta2024agent,
  title={Agent q: Advanced reasoning and learning for autonomous ai agents},
  author={Putta, Pranav and Mills, Edmund and Garg, Naman and Motwani, Sumeet and Finn, Chelsea and Garg, Divyansh and Rafailov, Rafael},
  journal={arXiv preprint arXiv:2408.07199},
  year={2024}
}

@article{koh2024tree,
  title={Tree search for language model agents},
  author={Koh, Jing Yu and McAleer, Stephen and Fried, Daniel and Salakhutdinov, Ruslan},
  journal={arXiv preprint arXiv:2407.01476},
  year={2024}
}

@article{gu2024your,
  title={Is your llm secretly a world model of the internet? model-based planning for web agents},
  author={Gu, Yu and Zheng, Boyuan and Gou, Boyu and Zhang, Kai and Chang, Cheng and Srivastava, Sanjari and Xie, Yanan and Qi, Peng and Sun, Huan and Su, Yu},
  journal={arXiv preprint arXiv:2411.06559},
  year={2024}
}

@article{murty2024nnetscape,
  title={Nnetscape navigator: Complex demonstrations for web agents without a demonstrator},
  author={Murty, Shikhar and Bahdanau, Dzmitry and Manning, Christopher D},
  journal={arXiv preprint arXiv:2410.02907},
  year={2024}
}

@article{qinghong2024showui,
  title={ShowUI: One Vision-Language-Action Model for GUI Visual Agent},
  author={Qinghong Lin, Kevin and Li, Linjie and Gao, Difei and Yang, Zhengyuan and Wu, Shiwei and Bai, Zechen and Lei, Weixian and Wang, Lijuan and Shou, Mike Zheng},
  journal={arXiv e-prints},
  pages={arXiv--2411},
  year={2024}
}

@inproceedings{chen2024spa,
  title={Spa-bench: A comprehensive benchmark for smartphone agent evaluation},
  author={Chen, Jingxuan and Yuen, Derek and Xie, Bin and Yang, Yuhao and Chen, Gongwei and Wu, Zhihao and Yixing, Li and Zhou, Xurui and Liu, Weiwen and Wang, Shuai and others},
  booktitle={NeurIPS 2024 Workshop on Open-World Agents}
}

@article{reddy2024infogent,
  title={Infogent: An agent-based framework for web information aggregation},
  author={Reddy, Revanth Gangi and Mukherjee, Sagnik and Kim, Jeonghwan and Wang, Zhenhailong and Hakkani-Tur, Dilek and Ji, Heng},
  journal={arXiv preprint arXiv:2410.19054},
  year={2024}
}

@article{patel2024large,
  title={Large Language Models Can Self-Improve At Web Agent Tasks},
  author={Patel, Ajay and Hofmarcher, Markus and Leoveanu-Condrei, Claudiu and Dinu, Marius-Constantin and Callison-Burch, Chris and Hochreiter, Sepp},
  journal={arXiv preprint arXiv:2405.20309},
  year={2024}
}

@article{abuelsaad2024agent,
  title={Agent-e: From autonomous web navigation to foundational design principles in agentic systems},
  author={Abuelsaad, Tamer and Akkil, Deepak and Dey, Prasenjit and Jagmohan, Ashish and Vempaty, Aditya and Kokku, Ravi},
  journal={arXiv preprint arXiv:2407.13032},
  year={2024}
}

@article{lin2024videogui,
  title={VideoGUI: A Benchmark for GUI Automation from Instructional Videos},
  author={Lin, Kevin Qinghong and Li, Linjie and Gao, Difei and Wu, Qinchen and Yan, Mingyi and Yang, Zhengyuan and Wang, Lijuan and Shou, Mike Zheng},
  journal={arXiv preprint arXiv:2406.10227},
  year={2024}
}

@inproceedings{chen2024webvln,
  title={Webvln: Vision-and-language navigation on websites},
  author={Chen, Qi and Pitawela, Dileepa and Zhao, Chongyang and Zhou, Gengze and Chen, Hsiang-Ting and Wu, Qi},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={2},
  pages={1165--1173},
  year={2024}
}

@article{chezelles2024browsergym,
  title={The BrowserGym Ecosystem for Web Agent Research},
  author={Chezelles, De and Le Sellier, Thibault and Gasse, Maxime and Lacoste, Alexandre and Drouin, Alexandre and Caccia, Massimo and Boisvert, L{\'e}o and Thakkar, Megh and Marty, Tom and Assouel, Rim and others},
  journal={arXiv preprint arXiv:2412.05467},
  year={2024}
}

@article{he2024webvoyager,
  title={WebVoyager: Building an End-to-End Web Agent with Large Multimodal Models},
  author={He, Hongliang and Yao, Wenlin and Ma, Kaixin and Yu, Wenhao and Dai, Yong and Zhang, Hongming and Lan, Zhenzhong and Yu, Dong},
  journal={arXiv preprint arXiv:2401.13919},
  year={2024}
}

@inproceedings{lai2024autowebglm,
  title={AutoWebGLM: A Large Language Model-based Web Navigating Agent},
  author={Lai, Hanyu and Liu, Xiao and Iong, Iat Long and Yao, Shuntian and Chen, Yuxuan and Shen, Pengbo and Yu, Hao and Zhang, Hanchen and Zhang, Xiaohan and Dong, Yuxiao and others},
  booktitle={Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
  pages={5295--5306},
  year={2024}
}

@article{yao2022webshop,
  title={Webshop: Towards scalable real-world web interaction with grounded language agents},
  author={Yao, Shunyu and Chen, Howard and Yang, John and Narasimhan, Karthik},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={20744--20757},
  year={2022}
}

@article{liu2024visualagentbench,
  title={Visualagentbench: Towards large multimodal models as visual foundation agents},
  author={Liu, Xiao and Zhang, Tianjie and Gu, Yu and Iong, Iat Long and Xu, Yifan and Song, Xixuan and Zhang, Shudan and Lai, Hanyu and Liu, Xinyi and Zhao, Hanlin and others},
  journal={arXiv preprint arXiv:2408.06327},
  year={2024}
}

@inproceedings{st2000user,
  title={The user interface as an agent environment},
  author={St. Amant, Robert and Zettlemoyer, Luke S},
  booktitle={Proceedings of the fourth international conference on Autonomous agents},
  pages={483--490},
  year={2000}
}

@inproceedings{riedl2002toward,
  title={Toward automated exploration of interactive systems},
  author={Riedl, Mark O and St. Amant, Robert},
  booktitle={Proceedings of the 7th international conference on Intelligent user interfaces},
  pages={135--142},
  year={2002}
}


@InProceedings{pmlr-v162-humphreys22a,
  title = 	 {A data-driven approach for learning to control computers},
  author =       {Humphreys, Peter C and Raposo, David and Pohlen, Tobias and Thornton, Gregory and Chhaparia, Rachita and Muldal, Alistair and Abramson, Josh and Georgiev, Petko and Santoro, Adam and Lillicrap, Timothy},
  booktitle = 	 {Proceedings of the 39th International Conference on Machine Learning},
  pages = 	 {9466--9482},
  year = 	 {2022},
  editor = 	 {Chaudhuri, Kamalika and Jegelka, Stefanie and Song, Le and Szepesvari, Csaba and Niu, Gang and Sabato, Sivan},
  volume = 	 {162},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {17--23 Jul},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v162/humphreys22a/humphreys22a.pdf},
  url = 	 {https://proceedings.mlr.press/v162/humphreys22a.html},
  abstract = 	 {It would be useful for machines to use computers as humans do so that they can aid us in everyday tasks. This is a setting in which there is also the potential to leverage large-scale expert demonstrations and human judgements of interactive behaviour, which are two ingredients that have driven much recent success in AI. Here we investigate the setting of computer control using keyboard and mouse, with goals specified via natural language. Instead of focusing on hand-designed curricula and specialized action spaces, we focus on developing a scalable method centered on reinforcement learning combined with behavioural priors informed by actual human-computer interactions. We achieve state-of-the-art and human-level mean performance across all tasks within the MiniWob++ benchmark, a challenging suite of computer control problems, and find strong evidence of cross-task transfer. These results demonstrate the usefulness of a unified human-agent interface when training machines to use computers. Altogether our results suggest a formula for achieving competency beyond MiniWob++ and towards controlling computers, in general, as a human would.}
}

@INPROCEEDINGS{9402046,
  author={Zheng, Yan and Liu, Yi and Xie, Xiaofei and Liu, Yepang and Ma, Lei and Hao, Jianye and Liu, Yang},
  booktitle={2021 IEEE/ACM 43rd International Conference on Software Engineering (ICSE)}, 
  title={Automatic Web Testing Using Curiosity-Driven Reinforcement Learning}, 
  year={2021},
  volume={},
  number={},
  pages={423-435},
  keywords={Location awareness;Software as a service;Reinforcement learning;Manuals;Task analysis;Testing;Software engineering;Web testing;Reinforcement Learning;Curiosity;Exploration;Software Engineering},
  doi={10.1109/ICSE43902.2021.00048}}

@inproceedings{NEURIPS2021_21834461,
 author = {Gur, Izzeddin and Jaques, Natasha and Miao, Yingjie and Choi, Jongwook and Tiwari, Manoj  and Lee, Honglak and Faust, Aleksandra},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {M. Ranzato and A. Beygelzimer and Y. Dauphin and P.S. Liang and J. Wortman Vaughan},
 pages = {4157--4169},
 publisher = {Curran Associates, Inc.},
 title = {Environment Generation for Zero-Shot Compositional Reinforcement Learning},
 url = {https://proceedings.neurips.cc/paper_files/paper/2021/file/218344619d8fb95d504ccfa11804073f-Paper.pdf},
 volume = {34},
 year = {2021}
}


@inproceedings{dean2022don,
  title={Don't Freeze Your Embedding: Lessons from Policy Finetuning in Environment Transfer},
  year=2022,
  author={Dean, Victoria and Toyama, Daniel Kenji and Precup, Doina},
  booktitle={ICLR Workshop on Agent Learning in Open-Endedness}
}

@inproceedings{li2021glider,
  title={Glider: A reinforcement learning approach to extract UI scripts from websites},
  author={Li, Yuanchun and Riva, Oriana},
  booktitle={Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval},
  pages={1420--1430},
  year={2021}
}

@inproceedings{jiadom,
  title={DOM-Q-NET: Grounded RL on Structured Language},
  year=2019,
  author={Jia, Sheng and Kiros, Jamie Ryan and Ba, Jimmy},
  booktitle={International Conference on Learning Representations}
}

@article{iki2022berts,
  title={Do BERTs learn to use browser user interface? Exploring multi-step tasks with unified vision-and-language berts},
  author={Iki, Taichi and Aizawa, Akiko},
  journal={arXiv preprint arXiv:2203.07828},
  year={2022}
}

@article{achiam2023gpt,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}

@article{claude3,
  title={The Claude 3 Model Family: Opus, Sonnet, Haiku},
  author={Anthropic},
  journal={https://www-cdn.anthropic.com},
  url={https://www-cdn.anthropic.com/de8ba9b01c9ab7cbabf5c33b80b7bbc618857627/Model_Card_Claude_3.pdf},
  year={2024}
}

@article{alayrac2022flamingo,
  title={Flamingo: a visual language model for few-shot learning},
  author={Alayrac, Jean-Baptiste and Donahue, Jeff and Luc, Pauline and Miech, Antoine and Barr, Iain and Hasson, Yana and Lenc, Karel and Mensch, Arthur and Millican, Katherine and Reynolds, Malcolm and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={23716--23736},
  year={2022}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@article{kojima2022large,
  title={Large language models are zero-shot reasoners},
  author={Kojima, Takeshi and Gu, Shixiang Shane and Reid, Machel and Matsuo, Yutaka and Iwasawa, Yusuke},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={22199--22213},
  year={2022}
}

@article{hoffmann2022training,
  title={Training compute-optimal large language models},
  author={Hoffmann, Jordan and Borgeaud, Sebastian and Mensch, Arthur and Buchatskaya, Elena and Cai, Trevor and Rutherford, Eliza and Casas, Diego de Las and Hendricks, Lisa Anne and Welbl, Johannes and Clark, Aidan and others},
  journal={arXiv preprint arXiv:2203.15556},
  year={2022}
}

@article{schick2023toolformer,
  title={Toolformer: Language models can teach themselves to use tools},
  author={Schick, Timo and Dwivedi-Yu, Jane and Dess{\`\i}, Roberto and Raileanu, Roberta and Lomeli, Maria and Hambro, Eric and Zettlemoyer, Luke and Cancedda, Nicola and Scialom, Thomas},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={68539--68551},
  year={2023}
}

@inproceedings{siegel2003sense,
  title={The sense-think-act paradigm revisited},
  author={Siegel, Mel},
  booktitle={1st International Workshop on Robotic Sensing, 2003. ROSE'03.},
  pages={5--pp},
  year={2003},
  organization={IEEE}
}

@article{hurst2024gpt,
  title={Gpt-4o system card},
  author={Hurst, Aaron and Lerer, Adam and Goucher, Adam P and Perelman, Adam and Ramesh, Aditya and Clark, Aidan and Ostrow, AJ and Welihinda, Akila and Hayes, Alan and Radford, Alec and others},
  journal={arXiv preprint arXiv:2410.21276},
  year={2024}
}

@article{wang2024qwen2,
  title={Qwen2-vl: Enhancing vision-language model's perception of the world at any resolution},
  author={Wang, Peng and Bai, Shuai and Tan, Sinan and Wang, Shijie and Fan, Zhihao and Bai, Jinze and Chen, Keqin and Liu, Xuejing and Wang, Jialin and Ge, Wenbin and others},
  journal={arXiv preprint arXiv:2409.12191},
  year={2024}
}

@article{rafailov2024direct,
  title={Direct preference optimization: Your language model is secretly a reward model},
  author={Rafailov, Rafael and Sharma, Archit and Mitchell, Eric and Manning, Christopher D and Ermon, Stefano and Finn, Chelsea},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@misc{zhang2024webpilotversatileautonomousmultiagent,
      title={WebPilot: A Versatile and Autonomous Multi-Agent System for Web Task Execution with Strategic Exploration}, 
      author={Yao Zhang and Zijian Ma and Yunpu Ma and Zhen Han and Yu Wu and Volker Tresp},
      year={2024},
      eprint={2408.15978},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2408.15978}, 
}

@misc{wang2024agentworkflowmemory,
      title={Agent Workflow Memory}, 
      author={Zora Zhiruo Wang and Jiayuan Mao and Daniel Fried and Graham Neubig},
      year={2024},
      eprint={2409.07429},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2409.07429}, 
}

@article{yang2023set,
  title={Set-of-mark prompting unleashes extraordinary visual grounding in gpt-4v},
  author={Yang, Jianwei and Zhang, Hao and Li, Feng and Zou, Xueyan and Li, Chunyuan and Gao, Jianfeng},
  journal={arXiv preprint arXiv:2310.11441},
  year={2023}
}

@misc{lutz2024wilburadaptiveincontextlearning,
      title={WILBUR: Adaptive In-Context Learning for Robust and Accurate Web Agents}, 
      author={Michael Lutz and Arth Bohra and Manvel Saroyan and Artem Harutyunyan and Giovanni Campagna},
      year={2024},
      eprint={2404.05902},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2404.05902}, 
}

@article{hare2019dealing,
  title={Dealing with sparse rewards in reinforcement learning},
  author={Hare, Joshua},
  journal={arXiv preprint arXiv:1910.09281},
  year={2019}
}

@article{minsky1961steps,
  title={Steps toward artificial intelligence},
  author={Minsky, Marvin},
  journal={Proceedings of the IRE},
  volume={49},
  number={1},
  pages={8--30},
  year={1961},
  publisher={IEEE}
}

@article{reddy2018shared,
  title={Shared autonomy via deep reinforcement learning},
  author={Reddy, Siddharth and Dragan, Anca D and Levine, Sergey},
  journal={arXiv preprint arXiv:1802.01744},
  year={2018}
}

@book{sutton2018reinforcement,
  title={Reinforcement Learning: An Introduction, Second Edition},
  author={Sutton, Richard S. and Barto, Andrew G.},
  publisher = {The MIT Press},
isbn={9780262039246},
  year={2018}
}

@article{michigan2021sneaker,
  title={Sneaker Bots \& Botnets: Malicious Digital Tools That Harm Rather than Help E-Commerce},
  author={Michigan, Sarah E},
  journal={Rutgers Bus. LJ},
  volume={17},
  pages={169},
  year={2021},
  publisher={HeinOnline}
}

@article{xiao2024towards,
  title={Towards Visual Grounding: A Survey},
  author={Xiao, Linhui and Yang, Xiaoshan and Lan, Xiangyuan and Wang, Yaowei and Xu, Changsheng},
  journal={arXiv preprint arXiv:2412.20206},
  year={2024}
}

@misc{marino2025computeruse,
        author={Marino, Kenneth and Marasović, Ana},
        title={Computer Use Survey: A Visual Survey of Computer Use Agents},
        year={2025},
        url={https://kennethmarino.com/computeruse/computeruse.html}
        }

@inproceedings{ross2011reduction,
  title={A reduction of imitation learning and structured prediction to no-regret online learning},
  author={Ross, St{\'e}phane and Gordon, Geoffrey and Bagnell, Drew},
  booktitle={Proceedings of the fourteenth international conference on artificial intelligence and statistics},
  pages={627--635},
  year={2011},
  organization={JMLR Workshop and Conference Proceedings}
}

@article{xu2024crab,
  title={Crab: Cross-environment agent benchmark for multimodal language model agents},
  author={Xu, Tianqi and Chen, Linyao and Wu, Dai-Jie and Chen, Yanjun and Zhang, Zecheng and Yao, Xiang and Xie, Zhiqiang and Chen, Yongchao and Liu, Shilong and Qian, Bochen and others},
  journal={arXiv preprint arXiv:2407.01511},
  year={2024}
}

@article{sager2025comprehensive,
  title={A Comprehensive Survey of Agents for Computer Use: Foundations, Challenges, and Future Directions},
  author={Sager, Pascal J and Meyer, Benjamin and Yan, Peng and von Wartburg-Kottler, Rebekka and Etaiwi, Layan and Enayati, Aref and Nobel, Gabriel and Abdulkadir, Ahmed and Grewe, Benjamin F and Stadelmann, Thilo},
  journal={arXiv preprint arXiv:2501.16150},
  year={2025}
}

@inproceedings{hu2025agents,
  title={Os agents: A survey on mllm-based agents for computer, phone and browser use},
  author={Hu, Xueyu and Xiong, Tao and Yi, Biao and Wei, Zishu and Xiao, Ruixuan and Chen, Yurun and Ye, Jiasheng and Tao, Meiling and Zhou, Xiangxin and Zhao, Ziyu and others},
  booktitle={Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={7436--7465},
  year={2025}
}

@article{yehudai2025survey,
  title={Survey on evaluation of llm-based agents},
  author={Yehudai, Asaf and Eden, Lilach and Li, Alan and Uziel, Guy and Zhao, Yilun and Bar-Haim, Roy and Cohan, Arman and Shmueli-Scheuer, Michal},
  journal={arXiv preprint arXiv:2503.16416},
  year={2025}
}

@article{touvron2023llama,
  title={Llama 2: Open Foundation and Fine-Tuned Chat Models},
  author={Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and others},
  journal={arXiv preprint arXiv:2307.09288},
  year={2023}
}

@article{grattafiori2024llama,
  title={The Llama 3 Herd of Models},
  author={Grattafiori, Aaron and Dubey, Abhimanyu and Jauhri, Abhinav and Pandey, Abhinav and Kadian, Abhishek and Al-Dahle, Ahmad and Letman, Aiesha and Mathur, Akhil and Schelten, Alan and Vaughan, Alex and others},
  journal={arXiv preprint arXiv:2407.21783},
  year={2024}
}

@article{shen2024scribeagent,
  title={ScribeAgent: Towards Specialized Web Agents Using Production-Scale Workflow Data},
  author={Shen, Junhong and Jain, Atishay and Xiao, Zedian and Amlekar, Ishan and Hadji, Mouad and Podolny, Aaron and Talwalkar, Ameet},
  journal={arXiv preprint arXiv:2411.15004},
  year={2024}
}

@article{zhang2025symbiotic,
  title={Symbiotic Cooperation for Web Agents: Harnessing Complementary Strengths of Large and Small LLMs},
  author={Zhang, Ruichen and Qiu, Mufan and Tan, Zhen and Zhang, Mohan and Lu, Vincent and Peng, Jie and Xu, Kaidi and Agudelo, Leandro Z and Qian, Peter and Chen, Tianlong},
  journal={arXiv preprint arXiv:2502.07942},
  year={2025}
}

@article{su2025learn,
  title={Learn-by-interact: A Data-Centric Framework for Self-Adaptive Agents in Realistic Environments},
  author={Su, Hongjin and Sun, Ruoxi and Yoon, Jinsung and Yin, Pengcheng and Yu, Tao and Ar{\i}k, Sercan {\"O}},
  journal={arXiv preprint arXiv:2501.10893},
  year={2025}
}

@article{yang2024agentoccam,
  title={AgentOccam: A Simple Yet Strong Baseline for LLM-Based Web Agents},
  author={Yang, Ke and Liu, Yao and Chaudhary, Sapana and Fakoor, Rasool and Chaudhari, Pratik and Karypis, George and Rangwala, Huzefa},
  journal={arXiv preprint arXiv:2410.13825},
  year={2024}
}

@misc{opencua2025,
  title={OpenCUA: Open Foundations for Computer-Use Agents},
  author={Wang, Xinyuan and Wang, Bowen and Lu, Dunjie and others},
  howpublished={\url{https://opencua.xlang.ai/}},
  year={2025}
}

@article{guo2024seed,
  title={Seed1.5-VL Technical Report},
  author={Guo, Dong and Wu, Faming and Zhu, Feida and Leng, Fuxing and Shi, Guang and Chen, Haobin and Fan, Haoqi and Wang, Jian and Jiang, Jianyu and Wang, Jiawei and others},
  journal={arXiv preprint arXiv:2505.07062},
  year={2024}
}

@misc{imagenet2009,
  title={ImageNet: A large-scale hierarchical image database},
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle={IEEE Conference on Computer Vision and Pattern Recognition},
  year={2009}
}

@misc{agentnetdocs,
  title={AgentNet Documentation - Annotation Requirements},
  howpublished={\url{https://junliwang.tech/agentnet-docs/requirements/annotation/annotation/}},
  year={2024}
}
@article{gur2021environment,
  title={Environment Generation for Zero-Shot Compositional Reinforcement Learning},
  author={Gur, Izzeddin and Jaques, Natasha and Miao, Kevin and Choi, Jongwook and Tomar, Manoj and Faust, Aleksandra and Nachum, Ofir},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

@article{zheng2021synergistic,
  title={Synergistic Integration of Long-Term Memory and Curiosity for Training-Free Web Agents},
  author={Zheng, Boyuan and others},
  journal={arXiv preprint},
  year={2021}
}

@article{gur2018learning,
  title={Learning to Navigate the Web},
  author={Gur, Izzeddin and Rückert, Ulrich and Faust, Aleksandra and Hakkani-Tür, Dilek},
  journal={arXiv preprint arXiv:1812.09195},
  year={2018}
}

@misc{kiela2024ai,
  title={AI Agents Are Here. What Now?},
  author={Kiela, Douwe and others},
  howpublished={\url{https://huggingface.co/blog/ethics-soc-7}},
  year={2024}
}
